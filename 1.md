# Efficient RL post-training
#Hardware_topics #GPU-side #Networking #System_Runtime #RL_training_phases #Weight_Synchrony

## Journey to 2-second Inter-node RL Weight Transfer
[Journey to 2-second Inter-node RL Weight Transfer](https://le.qun.ch/en/blog/2025/09/07/rl-weight-transfer/)

**Summary:** This article focuses on optimizing inter-node weight transfer for reinforcement learning training, achieving transfer times under 2 seconds. The key technical aspects include:

- **GPU Operations:** Three-stage tensor transfer process involving GPU operation queuing and execution
- **RDMA Networking:** Leveraging Remote Direct Memory Access for zero-copy, high-throughput transfers
- **System Optimization:** Low-latency transfers driven by training nodes without control logic on inference nodes

**Key Technical Insights:**
- Each tensor transfer involves enqueue GPU ops → wait for GPU ops & submit RDMA → wait for RDMA
- Zero-copy transfer mechanism for optimal performance
- Focus on reducing weight synchronization overhead in distributed RL training

**Relevance to Efficient RL Post-training:** This work directly addresses the weight synchronization bottleneck in distributed RL training, which is critical for efficient post-training of large RL models across multiple nodes.